{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES = ['Delaware', 'District of Columbia', 'Maryland', 'North Carolina', 'Virginia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_census_data(\n",
    "    endpoint=\"2021/acs/acs5\",\n",
    "    get_vars=\"NAME,B19013_001E\",\n",
    "    for_clause=\"place:*\",\n",
    "    in_clause=\"state:*\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Retrieves data from the U.S. Census Bureau API and returns it as a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        endpoint (str): The specific API endpoint (e.g., \"2021/acs/acs5\").\n",
    "        get_vars (str): Comma-separated list of variables to retrieve.\n",
    "        for_clause (str): The 'for' clause specifying the geography.\n",
    "        in_clause (str): The 'in' clause specifying nested geographies (optional).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the requested Census data.\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.census.gov/data/\"\n",
    "    url = base_url + endpoint\n",
    "    params = {\n",
    "        \"get\": get_vars,\n",
    "        \"for\": for_clause\n",
    "    }\n",
    "    if in_clause:\n",
    "        params[\"in\"] = in_clause\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "    # Parse the JSON response. The first row is the header.\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_acs_data():\n",
    "    # Retrieve data for income, population, age, and education.\n",
    "    df = get_census_data(\n",
    "        endpoint=\"2021/acs/acs5\",\n",
    "        get_vars=(\n",
    "            \"NAME,\"\n",
    "            \"B19013_001E,\"  # Median Household Income\n",
    "            \"B19301_001E,\"  # Per Capita Income\n",
    "            \"B01003_001E,\"  # Total Population\n",
    "            \"B01002_001E,\"  # Median Age\n",
    "            \"B15003_001E,\"  # Total Population 25+ (Education Universe)\n",
    "            \"B15003_022E\"   # Number with at least a Bachelor's Degree\n",
    "        ),\n",
    "        for_clause=\"place:*\",\n",
    "        in_clause=\"state:*\"\n",
    "    )\n",
    "\n",
    "    # List of columns to convert to numeric.\n",
    "    numeric_cols = [\n",
    "        'B19013_001E',  # Median Household Income\n",
    "        'B19301_001E',  # Per Capita Income\n",
    "        'B01003_001E',  # Total Population\n",
    "        'B01002_001E',  # Median Age\n",
    "        'B15003_001E',  # Total Population 25+\n",
    "        'B15003_022E'   # Bachelor's Degree Count\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Rename columns for clarity.\n",
    "    # The API returns additional columns for geography; here we rename them as well.\n",
    "    df = df.rename(columns={\n",
    "        \"B19013_001E\": \"median_household_income\",\n",
    "        \"B19301_001E\": \"median_percapita_income\",\n",
    "        \"B01003_001E\": \"population\",\n",
    "        \"B01002_001E\": \"median_age\",\n",
    "        \"B15003_001E\": \"total_25_plus_education\",\n",
    "        \"B15003_022E\": \"bachelor_degree\",\n",
    "        # Rename the geography codes (which come from the 'for' and 'in' clauses).\n",
    "        \"state\": \"state_code\",\n",
    "        \"place\": \"place_code\"\n",
    "    })\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    # Create a unique GEOID by combining state and place codes.\n",
    "    # ACS state codes are 2 digits; place codes are usually 5 digits.\n",
    "    df[\"geoid\"] = df[\"state_code\"].str.zfill(2) + df[\"place_code\"].str.zfill(5)\n",
    "\n",
    "    # Process the NAME column to derive human-friendly \"town\" and \"state_name\".\n",
    "    # The NAME field often contains both the place name and the state abbreviation,\n",
    "    # so we split by comma: the first part is the town, and the last is the state name.\n",
    "    df[\"town\"] = df['name'].apply(lambda x: x.split(\",\")[0].strip())\n",
    "    df[\"state_name\"] = df['name'].apply(lambda x: x.split(\",\")[-1].strip())\n",
    "\n",
    "    # Define the order of columns to keep.\n",
    "    keep_cols = [\n",
    "        'geoid', 'name', 'state_code', 'place_code', 'state_name', 'town',\n",
    "        'median_household_income', 'median_percapita_income',\n",
    "        'population', 'median_age', 'total_25_plus_education', 'bachelor_degree'\n",
    "    ]\n",
    "    \n",
    "    return df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_town_names(df):\n",
    "    \"\"\"\n",
    "    Cleans the 'town' column in the DataFrame by:\n",
    "      1. Removing any of the following keywords (case-insensitive) as whole words:\n",
    "         'CDP', 'city and borough', 'city', 'town', 'borough',\n",
    "         'municipality', 'village', 'urban county', 'metro township'\n",
    "      2. Removing any content in parentheses.\n",
    "      3. Replacing multiple whitespace with a single space and trimming leading/trailing spaces.\n",
    "      \n",
    "    This ensures that for example, \"Georgetown town\" becomes \"Georgetown\" rather than \"George\".\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing a 'town' column.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with a cleaned 'town' column.\n",
    "    \"\"\"\n",
    "    remove_from_names = [\n",
    "        'CDP', 'city and borough', 'city', 'town', 'borough',\n",
    "        'municipality', 'village', 'urban county', 'metro township'\n",
    "    ]\n",
    "    \n",
    "    # Build regex pattern with word boundaries so that only whole words are matched.\n",
    "    # We use re.escape to ensure any special characters in the keywords are escaped.\n",
    "    pattern = r'\\b(?:' + '|'.join(map(re.escape, remove_from_names)) + r')\\b'\n",
    "    \n",
    "    # Remove the keywords (case-insensitive) that appear as whole words.\n",
    "    df['town'] = df['town'].str.replace(pattern, '', regex=True)\n",
    "    \n",
    "    # Remove any content inside parentheses (including the parentheses)\n",
    "    df['town'] = df['town'].str.replace(r'\\(.*?\\)', '', regex=True)\n",
    "    \n",
    "    # Replace multiple whitespace with a single space.\n",
    "    df['town'] = df['town'].str.replace(r'\\s+', ' ', regex=True)\n",
    "    \n",
    "    # Trim leading and trailing whitespace.\n",
    "    df['town'] = df['town'].str.strip()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_acs(df, states):\n",
    "    \"\"\"\n",
    "    Filters the given DataFrame to include only rows where the 'state_name' column matches the provided list of states.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing a column named 'state_name'.\n",
    "    states (list): A list of state names to filter the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A new DataFrame containing only the rows where 'state_name' is in the provided list.\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    new_df = new_df.loc[new_df['state_name'].isin(states)]\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Retrieves, cleans, filters, and saves ACS data.\n",
    "\n",
    "    This function:\n",
    "    1. Fetches ACS data using `get_acs_data()`.\n",
    "    2. Cleans town names using `clean_town_names()`.\n",
    "    3. Filters the data for the specified states using `filter_acs()`.\n",
    "    4. Saves the processed DataFrame as a CSV file in the 'data' directory.\n",
    "\n",
    "    The script also ensures that the 'src' directory is added to the system path.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "    # Process the ACS data\n",
    "    df_acs = (\n",
    "        get_acs_data()\n",
    "        .pipe(clean_town_names)\n",
    "        .pipe(filter_acs, states=STATES)\n",
    "    )\n",
    "\n",
    "    # Define the file path and save to CSV\n",
    "    filepath = os.path.join('..', 'data', 'acs_raw.csv')\n",
    "    df_acs.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
